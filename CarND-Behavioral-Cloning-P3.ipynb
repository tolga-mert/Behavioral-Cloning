{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read driving data\n",
    "# Catalogs with driving data:\n",
    "drive_data_02 = 'drive-data-2'\n",
    "drive_data_03 = 'drive-data-3'\n",
    "# Log:\n",
    "driving_log = '/driving_log.csv'\n",
    "\n",
    "datasets = [drive_data_02, drive_data_03]\n",
    "\n",
    "print('Loading datasets...')\n",
    "samples = []\n",
    "for dataset in datasets:\n",
    "    ds = []\n",
    "    with open(dataset + driving_log) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            ds.append(line)\n",
    "        print('Dataset: {0} ({1} records)'.format(dataset, len(ds)))\n",
    "        samples.extend(ds)\n",
    "print('Loading completed ({0} records from {1} datasets)'.format(len(samples), len(datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split off 20% of the data to use for a test set.\n",
    "train_samples, validation_samples = train_test_split(samples, test_size = 0.2)\n",
    "print('Training records (no augmentation): {0}'.format(len(train_samples)))\n",
    "print('Validation records (no augmentation): {0}'.format(len(validation_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update path to an image\n",
    "def update_img_path(path):\n",
    "    upd_path = path.split('/')[-3] + '/' + \\\n",
    "               path.split('/')[-2] + '/' + \\\n",
    "               path.split('/')[-1]\n",
    "    return upd_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot row (1x3) of images with titles\n",
    "def plot_row_3(pics, titles):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(0, 3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(titles[i], wrap=True)\n",
    "        plt.imshow(pics[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    # Loop forever so the generator never terminates:\n",
    "    show_plot = True\n",
    "    \n",
    "    while 1:\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                # Extract the fourth token (Steering Angle)\n",
    "                angle_center = float(batch_sample[3])\n",
    "\n",
    "                # Create adjusted steering measurements for the side camera images\n",
    "                correction = 0.2                         # parameter to tune:\n",
    "                angle_left = angle_center + correction\n",
    "                angle_right = angle_center - correction\n",
    "\n",
    "                # Read in images from center, left and right cameras\n",
    "                path_center, path_left, path_right = batch_sample[0], batch_sample[1], batch_sample[2]\n",
    "                \n",
    "                # Update path to an images\n",
    "                path_center = update_img_path(path_center)\n",
    "                path_left   = update_img_path(path_left)\n",
    "                path_right  = update_img_path(path_right)\n",
    "                \n",
    "                # Use OpenCV to load an images\n",
    "                #img_center = cv2.imread(path_center)\n",
    "                img_center = cv2.cvtColor(cv2.imread(path_center), cv2.COLOR_BGR2RGB)\n",
    "                #img_left   = cv2.imread(path_left)\n",
    "                img_left   = cv2.cvtColor(cv2.imread(path_left), cv2.COLOR_BGR2RGB)\n",
    "                #img_right  = cv2.imread(path_right)\n",
    "                img_right  = cv2.cvtColor( cv2.imread(path_right), cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Plot example of input and augmented images\n",
    "                if show_plot:\n",
    "                    pics = [img_center, img_left, img_right]\n",
    "                    titles = ['Center camera (ang = {0})'.format(angle_center), \n",
    "                              'Left camera (ang = {0})'.format(angle_left), \n",
    "                              'Right camera (ang = {0})'.format(angle_right)]\n",
    "                    plot_row_3(pics, titles)\n",
    "                    pics = [np.fliplr(img_center), np.fliplr(img_left), np.fliplr(img_right)]\n",
    "                    titles = ['Center camera (ang = {0})'.format(-angle_center), \n",
    "                              'Left camera (ang = {0})'.format(-angle_left), \n",
    "                              'Right camera (ang = {0})'.format(-angle_right)]\n",
    "                    plot_row_3(pics, titles)\n",
    "                    show_plot = False\n",
    "\n",
    "                # Add Images and Angles to dataset\n",
    "                images.extend([img_center, img_left, img_right])\n",
    "                angles.extend([angle_center, angle_left, angle_right])\n",
    "\n",
    "            # Data augmentation\n",
    "            aug_images, aug_angles = [], []\n",
    "            for image, angle in zip(images, angles):\n",
    "                aug_images.append(image)\n",
    "                aug_angles.append(angle)\n",
    "                # Flipping Images (horizontally) and invert Steering Angles\n",
    "                aug_images.append(np.fliplr(image))\n",
    "                aug_angles.append(-angle)\n",
    "\n",
    "            # TODO: Trim image to only see section with road\n",
    "            # Convert Images and Steering measurements to NumPy arrays\n",
    "            # (the format Keras requires)\n",
    "            \n",
    "            X_train = np.array(aug_images)\n",
    "            y_train = np.array(aug_angles)\n",
    "            #X_train = np.array(images)\n",
    "            #y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the basic neural network to verify that everything is working\n",
    "# Flattened image connected to a single output node. This single output\n",
    "# node will predict steering angle, which makes this a regression network.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size = 32)\n",
    "validation_generator = generator(validation_samples, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# pixel_normalized = pixel / 255\n",
    "# pixel_mean_centered = pixel_normalized - 0.5\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape = (160, 320, 3)))\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "model.add(Convolution2D(24, 5, 5, subsample = (2, 2), activation = \"relu\"))\n",
    "model.add(Convolution2D(36, 5, 5, subsample = (2, 2), activation = \"relu\"))\n",
    "model.add(Convolution2D(48, 5, 5, subsample = (2, 2), activation = \"relu\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation = \"relu\"))\n",
    "model.add(Convolution2D(64, 3, 3, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(Convolution2D(6, 5, 5, activation = \"relu\"))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1164))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train model with the feature and label arrays.\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    samples_per_epoch = len(train_samples) * 6, \n",
    "    validation_data   = validation_generator,\n",
    "    nb_val_samples    = len(validation_samples) * 6, \n",
    "    nb_epoch          = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the train model\n",
    "model.save('model.h5')\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
